{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have completed a project of Machine Learning with spark ML, in this assignment, we will be swithing to the context of Deep Learning with Tensorflow/Keras by two tasks:\n",
    "- Task1: Image Classification with CNN\n",
    "- Task2: Image captioning with a combination of CNN and RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Going Deeper with convolutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before **Inception v1** (**GoogLeNet**), which is the winner of the **ILSVRC** (ImageNet Large Scale Visual Recognition Competition) in 2014, most popular CNNs just stacked convolution layers deeper and deeper, hoping to get better performance.\n",
    "The Inception network, however, uses a lot of tricks to improve performance in terms of speed and accuracy.\n",
    "Compared to other networks, **Inception v1** has significant improvement over **ZFNet** (the winner in 2013) and **AlexNet** (the winner in 2012), and has relatively lower error rate compared with the VGGNet.\n",
    "\n",
    "In this task, we will be implementing the inception architecture [in this paper](https://arxiv.org/abs/1409.4842) with TensorFlow/Keras. \n",
    "\n",
    "The goal of this task is to understand how to write code to build the model, as long as you can verify the correctness of the code (e.g., through Keras model summary), it is not necessary to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from lib.networks.base_network import Net\n",
    "\n",
    "\n",
    "class InceptionV1(Net):\n",
    "    def __init__(self, cfg_):\n",
    "        super().__init__(cfg_)\n",
    "        self.x = tf.placeholder(tf.float32, name='x', shape=[self.config.batch_size,\n",
    "                                                             self.config.image_width,\n",
    "                                                             self.config.image_height,\n",
    "                                                             self.config.image_depth], )\n",
    "        self.y = tf.placeholder(tf.int16, name='y', shape=[self.config.batch_size,\n",
    "                                                           self.config.n_classes])\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        self.summary = []\n",
    "\n",
    "    def init_saver(self):\n",
    "        pass\n",
    "\n",
    "    def get_summary(self):\n",
    "        return self.summary\n",
    "\n",
    "    def conv2d(self, layer_name, inputs, out_channels, kernel_size, strides=1, padding='SAME'):\n",
    "        in_channels = inputs.get_shape()[-1]\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            self.scope[layer_name] = scope\n",
    "            w = tf.get_variable(name='weights',\n",
    "                                trainable=True,\n",
    "                                shape=[kernel_size, kernel_size, in_channels, out_channels],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.get_variable(name='biases',\n",
    "                                trainable=True,\n",
    "                                shape=[out_channels],\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "            inputs = tf.nn.conv2d(inputs, w, [1, strides, strides, 1], padding=padding, name='conv')\n",
    "            inputs = tf.nn.bias_add(inputs, b, name='bias_add')\n",
    "            inputs = tf.nn.relu(inputs, name='relu')\n",
    "            return inputs\n",
    "\n",
    "    def max_pool(self, layer_name, inputs, pool_size, strides, padding='SAME'):\n",
    "        with tf.name_scope(layer_name):\n",
    "            return tf.nn.max_pool(inputs, [1, pool_size, pool_size, 1], [1, strides, strides, 1], padding=padding,\n",
    "                                  name=layer_name)\n",
    "\n",
    "    def avg_pool(self, layer_name, inputs, pool_size, strides, padding='SAME'):\n",
    "        with tf.name_scope(layer_name):\n",
    "            return tf.nn.avg_pool(inputs, [1, pool_size, pool_size, 1], [1, strides, strides, 1], padding=padding,\n",
    "                                  name=layer_name)\n",
    "\n",
    "    def lrn(self, layer_name, inputs, depth_radius=5, alpha=0.0001, beta=0.75):\n",
    "        with tf.name_scope(layer_name):\n",
    "            return tf.nn.local_response_normalization(name='pool1_norm1', input=inputs, depth_radius=depth_radius,\n",
    "                                                      alpha=alpha, beta=beta)\n",
    "\n",
    "    def concat(self, layer_name, inputs):\n",
    "        with tf.name_scope(layer_name):\n",
    "            one_by_one = inputs[0]\n",
    "            three_by_three = inputs[1]\n",
    "            five_by_five = inputs[2]\n",
    "            pooling = inputs[3]\n",
    "            return tf.concat([one_by_one, three_by_three, five_by_five, pooling], axis=3)\n",
    "\n",
    "    def dropout(self, layer_name, inputs, keep_prob):\n",
    "        # dropout_rate = 1 - keep_prob\n",
    "        with tf.name_scope(layer_name):\n",
    "            return tf.nn.dropout(name=layer_name, x=inputs, keep_prob=keep_prob)\n",
    "\n",
    "    def bn(self, layer_name, inputs, epsilon=1e-3):\n",
    "        with tf.name_scope(layer_name):\n",
    "            batch_mean, batch_var = tf.nn.moments(inputs, [0])\n",
    "            inputs = tf.nn.batch_normalization(inputs, mean=batch_mean, variance=batch_var, offset=None,\n",
    "                                               scale=None, variance_epsilon=epsilon)\n",
    "            return inputs\n",
    "\n",
    "    def fc(self, layer_name, inputs, out_nodes):\n",
    "        shape = inputs.get_shape()\n",
    "        if len(shape) == 4:  # x is 4D tensor\n",
    "            size = shape[1].value * shape[2].value * shape[3].value\n",
    "        else:  # x has already flattened\n",
    "            size = shape[-1].value\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            self.scope[layer_name] = scope\n",
    "            w = tf.get_variable('weights',\n",
    "                                shape=[size, out_nodes],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.get_variable('biases',\n",
    "                                shape=[out_nodes],\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "            flat_x = tf.reshape(inputs, [-1, size])\n",
    "            inputs = tf.nn.bias_add(tf.matmul(flat_x, w), b)\n",
    "            inputs = tf.nn.relu(inputs)\n",
    "            return inputs\n",
    "\n",
    "    def cal_loss(self, logits, labels):\n",
    "        with tf.name_scope('loss') as scope:\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=logits, labels=labels, name='cross-entropy')\n",
    "            self.loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "            loss_summary = tf.summary.scalar(scope, self.loss)\n",
    "            self.summary.append(loss_summary)\n",
    "\n",
    "    def cal_accuracy(self, logits, labels):\n",
    "        with tf.name_scope('accuracy') as scope:\n",
    "            correct = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "            correct = tf.cast(correct, tf.float32)\n",
    "            self.accuracy = tf.reduce_mean(correct) * 100.0\n",
    "            accuracy_summary = tf.summary.scalar(scope, self.accuracy)\n",
    "            self.summary.append(accuracy_summary)\n",
    "\n",
    "    def optimize(self):\n",
    "        with tf.name_scope('optimizer'):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.config.learning_rate)\n",
    "            # optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            train_op = optimizer.minimize(self.loss, global_step=self.global_step_tensor)\n",
    "            return train_op\n",
    "\n",
    "    def build_model(self):\n",
    "        conv1_7x7_s2 = self.conv2d('conv1_7x7_s2', self.x, 64, 7, 2)\n",
    "        pool1_3x3_s2 = self.max_pool('pool1_3x3_s2', conv1_7x7_s2, 3, 2)\n",
    "        pool1_norm1 = self.lrn('pool1_norm1', pool1_3x3_s2)\n",
    "        conv2_3x3_reduce = self.conv2d('conv2_3x3_reduce', pool1_norm1, 64, 1, 1)\n",
    "        conv2_3x3 = self.conv2d('conv2_3x3', conv2_3x3_reduce, 192, 3, 1)\n",
    "        conv2_norm2 = self.lrn('conv2_norm2', conv2_3x3)\n",
    "        pool2_3x3_s2 = self.max_pool('pool2_3x3_s2', conv2_norm2, 3, 2)\n",
    "\n",
    "        inception_3a_1x1 = self.conv2d('inception_3a_1x1', pool2_3x3_s2, 64, 1, 1)\n",
    "        inception_3a_3x3_reduce = self.conv2d('inception_3a_3x3_reduce', pool2_3x3_s2, 96, 1, 1)\n",
    "        inception_3a_3x3 = self.conv2d('inception_3a_3x3', inception_3a_3x3_reduce, 128, 3, 1)\n",
    "        inception_3a_5x5_reduce = self.conv2d('inception_3a_5x5_reduce', pool2_3x3_s2, 16, 1, 1)\n",
    "        inception_3a_5x5 = self.conv2d('inception_3a_5x5', inception_3a_5x5_reduce, 32, 5, 1)\n",
    "        inception_3a_pool = self.max_pool('inception_3a_pool', pool2_3x3_s2, 3, 1)\n",
    "        inception_3a_pool_proj = self.conv2d('inception_3a_pool_proj', inception_3a_pool, 32, 1, 1)\n",
    "        inception_3a_output = self.concat('inception_3a_output', [inception_3a_1x1, inception_3a_3x3, inception_3a_5x5,\n",
    "                                                                  inception_3a_pool_proj])\n",
    "\n",
    "        inception_3b_1x1 = self.conv2d('inception_3b_1x1', inception_3a_output, 128, 1, 1)\n",
    "        inception_3b_3x3_reduce = self.conv2d('inception_3b_3x3_reduce', inception_3a_output, 128, 1, 1)\n",
    "        inception_3b_3x3 = self.conv2d('inception_3b_3x3', inception_3b_3x3_reduce, 192, 3, 1)\n",
    "        inception_3b_5x5_reduce = self.conv2d('inception_3b_5x5_reduce', inception_3a_output, 32, 1, 1)\n",
    "        inception_3b_5x5 = self.conv2d('inception_3b_5x5', inception_3b_5x5_reduce, 96, 5, 1)\n",
    "        inception_3b_pool = self.max_pool('inception_3b_pool', inception_3a_output, 3, 1)\n",
    "        inception_3b_pool_proj = self.conv2d('inception_3b_pool_proj', inception_3b_pool, 64, 1, 1)\n",
    "        inception_3b_output = self.concat('inception_3b_output', [inception_3b_1x1, inception_3b_3x3, inception_3b_5x5,\n",
    "                                                                  inception_3b_pool_proj])\n",
    "\n",
    "        pool3_3x3_s2 = self.max_pool('pool3_3x3_s2', inception_3b_output, 3, 2)\n",
    "        inception_4a_1x1 = self.conv2d('inception_4a_1x1', pool3_3x3_s2, 192, 1, 1)\n",
    "        inception_4a_3x3_reduce = self.conv2d('inception_4a_3x3_reduce', pool3_3x3_s2, 96, 1, 1)\n",
    "        inception_4a_3x3 = self.conv2d('inception_4a_3x3', inception_4a_3x3_reduce, 208, 3, 1)\n",
    "        inception_4a_5x5_reduce = self.conv2d('inception_4a_5x5_reduce', pool3_3x3_s2, 16, 1, 1)\n",
    "        inception_4a_5x5 = self.conv2d('inception_4a_5x5', inception_4a_5x5_reduce, 48, 5, 1)\n",
    "        inception_4a_pool = self.max_pool('inception_4a_pool', pool3_3x3_s2, 3, 1)\n",
    "        inception_4a_pool_proj = self.conv2d('inception_4a_pool_proj', inception_4a_pool, 64, 1, 1)\n",
    "        inception_4a_output = self.concat('inception_4a_output', [inception_4a_1x1, inception_4a_3x3, inception_4a_5x5,\n",
    "                                                                  inception_4a_pool_proj])\n",
    "\n",
    "        inception_4b_1x1 = self.conv2d('inception_4b_1x1', inception_4a_output, 160, 1, 1)\n",
    "        inception_4b_3x3_reduce = self.conv2d('inception_4b_3x3_reduce', inception_4a_output, 112, 1, 1)\n",
    "        inception_4b_3x3 = self.conv2d('inception_4b_3x3', inception_4b_3x3_reduce, 224, 3, 1)\n",
    "        inception_4b_5x5_reduce = self.conv2d('inception_4b_5x5_reduce', inception_4a_output, 24, 1, 1)\n",
    "        inception_4b_5x5 = self.conv2d('inception_4b_5x5', inception_4b_5x5_reduce, 64, 5, 1)\n",
    "        inception_4b_pool = self.max_pool('inception_4b_pool', inception_4a_output, 3, 1)\n",
    "        inception_4b_pool_proj = self.conv2d('inception_4b_pool_proj', inception_4b_pool, 64, 1, 1)\n",
    "        inception_4b_output = self.concat('inception_4b_output', [inception_4b_1x1, inception_4b_3x3, inception_4b_5x5,\n",
    "                                                                  inception_4b_pool_proj])\n",
    "\n",
    "        inception_4c_1x1 = self.conv2d('inception_4c_1x1', inception_4b_output, 128, 1, 1)\n",
    "        inception_4c_3x3_reduce = self.conv2d('inception_4c_3x3_reduce', inception_4b_output, 128, 1, 1)\n",
    "        inception_4c_3x3 = self.conv2d('inception_4c_3x3', inception_4c_3x3_reduce, 256, 3, 1)\n",
    "        inception_4c_5x5_reduce = self.conv2d('inception_4c_5x5_reduce', inception_4b_output, 24, 1, 1)\n",
    "        inception_4c_5x5 = self.conv2d('inception_4c_5x5', inception_4c_5x5_reduce, 64, 5, 1)\n",
    "        inception_4c_pool = self.max_pool('inception_4c_pool', inception_4b_output, 3, 1)\n",
    "        inception_4c_pool_proj = self.conv2d('inception_4c_pool_proj', inception_4c_pool, 64, 1, 1)\n",
    "        inception_4c_output = self.concat('inception_4c_output', [inception_4c_1x1, inception_4c_3x3, inception_4c_5x5,\n",
    "                                                                  inception_4c_pool_proj])\n",
    "\n",
    "        inception_4d_1x1 = self.conv2d('inception_4d_1x1', inception_4c_output, 112, 1, 1)\n",
    "        inception_4d_3x3_reduce = self.conv2d('inception_4d_3x3_reduce', inception_4c_output, 144, 1, 1)\n",
    "        inception_4d_3x3 = self.conv2d('inception_4d_3x3', inception_4d_3x3_reduce, 288, 3, 1)\n",
    "        inception_4d_5x5_reduce = self.conv2d('inception_4d_5x5_reduce', inception_4c_output, 32, 1, 1)\n",
    "        inception_4d_5x5 = self.conv2d('inception_4d_5x5', inception_4d_5x5_reduce, 64, 5, 1)\n",
    "        inception_4d_pool = self.max_pool('inception_4d_pool', inception_4c_output, 3, 1)\n",
    "        inception_4d_pool_proj = self.conv2d('inception_4d_pool_proj', inception_4d_pool, 64, 1, 1)\n",
    "        inception_4d_output = self.concat('inception_4d_output', [inception_4d_1x1, inception_4d_3x3, inception_4d_5x5,\n",
    "                                                                  inception_4d_pool_proj])\n",
    "\n",
    "        inception_4e_1x1 = self.conv2d('inception_4e_1x1', inception_4d_output, 256, 1, 1)\n",
    "        inception_4e_3x3_reduce = self.conv2d('inception_4e_3x3_reduce', inception_4d_output, 160, 1, 1)\n",
    "        inception_4e_3x3 = self.conv2d('inception_4e_3x3', inception_4e_3x3_reduce, 320, 3, 1)\n",
    "        inception_4e_5x5_reduce = self.conv2d('inception_4e_5x5_reduce', inception_4d_output, 32, 1, 1)\n",
    "        inception_4e_5x5 = self.conv2d('inception_4e_5x5', inception_4e_5x5_reduce, 128, 5, 1)\n",
    "        inception_4e_pool = self.max_pool('inception_4e_pool', inception_4d_output, 3, 1)\n",
    "        inception_4e_pool_proj = self.conv2d('inception_4e_pool_proj', inception_4e_pool, 128, 1, 1)\n",
    "        inception_4e_output = self.concat('inception_4e_output', [inception_4e_1x1, inception_4e_3x3, inception_4e_5x5,\n",
    "                                                                  inception_4e_pool_proj])\n",
    "\n",
    "        pool4_3x3_s2 = self.max_pool('pool4_3x3_s2', inception_4e_output, 3, 2)\n",
    "        inception_5a_1x1 = self.conv2d('inception_5a_1x1', pool4_3x3_s2, 256, 1, 1)\n",
    "        inception_5a_3x3_reduce = self.conv2d('inception_5a_3x3_reduce', pool4_3x3_s2, 160, 1, 1)\n",
    "        inception_5a_3x3 = self.conv2d('inception_5a_3x3', inception_5a_3x3_reduce, 320, 3, 1)\n",
    "        inception_5a_5x5_reduce = self.conv2d('inception_5a_5x5_reduce', pool4_3x3_s2, 32, 1, 1)\n",
    "        inception_5a_5x5 = self.conv2d('inception_5a_5x5', inception_5a_5x5_reduce, 128, 5, 1)\n",
    "        inception_5a_pool = self.max_pool('inception_5a_pool', pool4_3x3_s2, 3, 1)\n",
    "        inception_5a_pool_proj = self.conv2d('inception_5a_pool_proj', inception_5a_pool, 128, 1, 1)\n",
    "        inception_5a_output = self.concat('inception_5a_output', [inception_5a_1x1, inception_5a_3x3, inception_5a_5x5,\n",
    "                                                                  inception_5a_pool_proj])\n",
    "\n",
    "        inception_5b_1x1 = self.conv2d('inception_5b_1x1', inception_5a_output, 384, 1, 1)\n",
    "        inception_5b_3x3_reduce = self.conv2d('inception_5b_3x3_reduce', inception_5a_output, 192, 1, 1)\n",
    "        inception_5b_3x3 = self.conv2d('inception_5b_3x3', inception_5b_3x3_reduce, 384, 3, 1)\n",
    "        inception_5b_5x5_reduce = self.conv2d('inception_5b_5x5_reduce', inception_5a_output, 48, 1, 1)\n",
    "        inception_5b_5x5 = self.conv2d('inception_5b_5x5', inception_5b_5x5_reduce, 128, 5, 1)\n",
    "        inception_5b_pool = self.max_pool('inception_5b_pool', inception_5a_output, 3, 1)\n",
    "        inception_5b_pool_proj = self.conv2d('inception_5b_pool_proj', inception_5b_pool, 128, 1, 1)\n",
    "        inception_5b_output = self.concat('inception_5b_output', [inception_5b_1x1, inception_5b_3x3, inception_5b_5x5,\n",
    "                                                                  inception_5b_pool_proj])\n",
    "\n",
    "        pool5_7x7_s1 = self.avg_pool('pool5_7x7_s1', inception_5b_output, 7, 1)\n",
    "        pool5_drop_7x7_s1 = self.dropout('pool5_drop_7x7_s1', pool5_7x7_s1, 0.6)\n",
    "\n",
    "        self.logits = self.fc('loss3_classifier', pool5_drop_7x7_s1, out_nodes=self.config.n_classes)\n",
    "\n",
    "        self.cal_loss(self.logits, self.y)\n",
    "        self.cal_accuracy(self.logits, self.y)\n",
    "        train_op = self.optimize()\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Show and Tell: A Neural Image Caption Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically describing the content of an image is a fundamental problem in AI that connects *computer vision* and *natural language processing*.\n",
    "In this task, we will be looking into how we can use CNNs and RNNs to build an Image Caption Generator.\n",
    "\n",
    "Specifically, you will be implementing and training the model [in this paper](https://arxiv.org/abs/1411.4555) with TensorFlow/Keras on one of the datasets mentioned in the paper.\n",
    "\n",
    "To lighten the burden on training the network, you can use any pretrained network in [tf.keras.applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
